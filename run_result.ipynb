{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tf_agents import policies\n",
    "\n",
    "saved_policy = tf.compat.v2.saved_model.load(\"policy\")\n",
    "get_initial_state_fn = saved_policy.signatures['get_initial_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction signature_wrapper(*, batch_size) at 0x1E29EBE9FD0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_initial_state_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clare\\anaconda3\\envs\\late-tf-env\\lib\\site-packages\\gym\\utils\\seeding.py:138: DeprecationWarning: \u001b[33mWARN: Function `hash_seed(seed, max_bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\clare\\anaconda3\\envs\\late-tf-env\\lib\\site-packages\\gym\\utils\\seeding.py:175: DeprecationWarning: \u001b[33mWARN: Function `_bigint_from_bytes(bytes)` is marked as deprecated and will be removed in the future. \u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "from tf_agents.environments.wrappers import ActionRepeat\n",
    "from gym.wrappers import TimeLimit\n",
    "from tf_agents.environments.atari_preprocessing import AtariPreprocessing\n",
    "from tf_agents.environments.atari_wrappers import FrameStack4\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import TFPyEnvironment\n",
    "\n",
    "class AtariPreprocessingWithSkipStart(AtariPreprocessing):\n",
    "    def skip_frames(self, num_skip):\n",
    "        for _ in range(num_skip):\n",
    "          super().step(0) # NOOP for num_skip steps\n",
    "    def reset(self, **kwargs):\n",
    "        obs = super().reset(**kwargs)\n",
    "        self.skip_frames(40)\n",
    "        return obs\n",
    "    def step(self, action):\n",
    "        lives_before_action = self.ale.lives()\n",
    "        obs, rewards, done, info = super().step(action)\n",
    "        if self.ale.lives() < lives_before_action and not done:\n",
    "            self.skip_frames(40)\n",
    "        return obs, rewards, done, info\n",
    "\n",
    "\n",
    "# repeating_env = ActionRepeat(env, times=4)\n",
    "limited_repeating_env = suite_gym.load(\n",
    "    \"ALE/SpaceInvaders-v5\",\n",
    "    gym_env_wrappers=[lambda env: TimeLimit(env, max_episode_steps=10000)],\n",
    "    env_wrappers=[lambda env: ActionRepeat(env, times=4)]\n",
    ")\n",
    "env = suite_gym.load(\n",
    "    'ALE/SpaceInvaders-v5',\n",
    "    max_episode_steps=27000,\n",
    "    gym_env_wrappers=[AtariPreprocessingWithSkipStart, FrameStack4]\n",
    ")\n",
    "tf_env = TFPyEnvironment(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tf_agents.networks.q_network import QNetwork\n",
    "\n",
    "preprocessing_layer = keras.layers.Lambda(lambda obs: tf.cast(obs, np.float32) / 255.) #Default layer design from book\n",
    "fc_layer_params = [512]\n",
    "conv_layer_params = [(32, (8, 8), 4), (64, (4, 4), 2), (64, (3, 3), 1)]\n",
    "q_net = QNetwork(\n",
    "    tf_env.observation_spec(),\n",
    "    tf_env.action_spec(),\n",
    "    preprocessing_layers=preprocessing_layer,\n",
    "    conv_layer_params=conv_layer_params,\n",
    "    fc_layer_params=fc_layer_params\n",
    ")\n",
    "from tf_agents.agents.dqn.dqn_agent import DqnAgent\n",
    "\n",
    "train_steps = tf.Variable(0)\n",
    "update_period = 4\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=2.5e-4, rho=0.95, momentum=0.0, epsilon=0.00001, centered=True)\n",
    "epsilon_fn = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=1.0,\n",
    "    decay_steps=250000 // update_period,\n",
    "    end_learning_rate=0.01)\n",
    "agent = DqnAgent(\n",
    "    time_step_spec=tf_env.time_step_spec(),\n",
    "    action_spec=tf_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    target_update_period=2000,\n",
    "    td_errors_loss_fn=keras.losses.Huber(reduction=\"none\"),\n",
    "    gamma=0.99,\n",
    "    train_step_counter=train_steps,\n",
    "    epsilon_greedy=lambda:epsilon_fn(train_steps)\n",
    ")\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Workspace\\Python\\Self-Invader-agent\\run_result.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workspace/Python/Self-Invader-agent/run_result.ipynb#ch0000003?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtf_agents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdrivers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdynamic_step_driver\u001b[39;00m \u001b[39mimport\u001b[39;00m DynamicStepDriver\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Workspace/Python/Self-Invader-agent/run_result.ipynb#ch0000003?line=6'>7</a>\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Workspace/Python/Self-Invader-agent/run_result.ipynb#ch0000003?line=8'>9</a>\u001b[0m agent\u001b[39m.\u001b[39mpolicy \u001b[39m=\u001b[39m saved_policy\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/Python/Self-Invader-agent/run_result.ipynb#ch0000003?line=10'>11</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mShowProgress\u001b[39;00m():\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Workspace/Python/Self-Invader-agent/run_result.ipynb#ch0000003?line=11'>12</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, total):\n",
      "File \u001b[1;32mc:\\Users\\clare\\anaconda3\\envs\\late-tf-env\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\autotrackable.py:69\u001b[0m, in \u001b[0;36mAutoTrackable.__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/clare/anaconda3/envs/late-tf-env/lib/site-packages/tensorflow/python/training/tracking/autotrackable.py?line=65'>66</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_self_setattr_tracking\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     <a href='file:///c%3A/Users/clare/anaconda3/envs/late-tf-env/lib/site-packages/tensorflow/python/training/tracking/autotrackable.py?line=66'>67</a>\u001b[0m   value \u001b[39m=\u001b[39m data_structures\u001b[39m.\u001b[39msticky_attribute_assignment(\n\u001b[0;32m     <a href='file:///c%3A/Users/clare/anaconda3/envs/late-tf-env/lib/site-packages/tensorflow/python/training/tracking/autotrackable.py?line=67'>68</a>\u001b[0m       trackable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, value\u001b[39m=\u001b[39mvalue, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m---> <a href='file:///c%3A/Users/clare/anaconda3/envs/late-tf-env/lib/site-packages/tensorflow/python/training/tracking/autotrackable.py?line=68'>69</a>\u001b[0m \u001b[39msuper\u001b[39;49m(AutoTrackable, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(name, value)\n",
      "\u001b[1;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver\n",
    "\n",
    "\n",
    "\n",
    "frames = []\n",
    "\n",
    "agent.policy = saved_policy\n",
    "\n",
    "class ShowProgress():\n",
    "    def __init__(self, total):\n",
    "        self.counter = 0\n",
    "        self.total = total\n",
    "    def __call__(self, trajectory):\n",
    "        if not trajectory.is_boundary():\n",
    "            self.counter += 1\n",
    "        if self.counter % 100 == 0:\n",
    "            print(\"\\r{}/{}\".format(self.counter, self.total), end=\"\")\n",
    "\n",
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=40):\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update_scene, fargs=(frames, patch),\n",
    "        frames=len(frames), repeat=repeat, interval=interval)\n",
    "    plt.close()\n",
    "    return anim\n",
    "\n",
    "def save_frames(trajectory):\n",
    "    global frames\n",
    "    frames.append(tf_env.pyenv.envs[0].render(mode=\"rgb_array\"))\n",
    "\n",
    "watch_driver = DynamicStepDriver(\n",
    "    tf_env,\n",
    "    agent.policy,\n",
    "    observers=[save_frames, ShowProgress(1000)],\n",
    "    num_steps=1000)\n",
    "final_time_step, final_policy_state = watch_driver.run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cff0a5753bbe1c482f45929baeb1d46965174c27b3e9cc4c8354a1ffea53b763"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('late-tf-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
